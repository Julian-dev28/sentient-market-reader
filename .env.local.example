# ── LLM Provider ─────────────────────────────────────────────────────────────
# anthropic | openai | grok | openrouter
AI_PROVIDER=grok

# Direct provider keys
XAI_API_KEY=
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...

# ── Model overrides (optional — defaults shown) ───────────────────────────────
# Anthropic  — latest fast: claude-haiku-4-5-20251001 | latest smart: claude-opus-4-6
ANTHROPIC_FAST_MODEL=claude-haiku-4-5-20251001
ANTHROPIC_SMART_MODEL=claude-sonnet-4-6

# OpenAI     — latest fast: gpt-5-mini (if access) | latest smart: gpt-5 / gpt-5.2 (if access)
OPENAI_FAST_MODEL=gpt-4o-mini
OPENAI_SMART_MODEL=gpt-4o

# Grok (xAI) — latest fast: grok-4-1-fast-non-reasoning | latest smart: grok-4-0709 / grok-4-1-fast-reasoning
GROK_FAST_MODEL=grok-3-fast
GROK_SMART_MODEL=grok-3

# OpenRouter — set AI_PROVIDER=openrouter and pick any model
OPENROUTER_API_KEY=sk-or-v1-...
OPENROUTER_MODEL=x-ai/grok-3          # smart tier  (default: anthropic/claude-sonnet-4-6)
OPENROUTER_FAST_MODEL=x-ai/grok-3-mini # fast tier   (default: OPENROUTER_MODEL)

# Python ROMA microservice (roma-dspy). Set to empty string to skip and use TypeScript ROMA fallback.
PYTHON_ROMA_URL=http://localhost:8001

CMC_API_KEY=
KALSHI_API_KEY=
KALSHI_PRIVATE_KEY_PATH=
