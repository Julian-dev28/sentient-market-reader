# ── LLM Provider ─────────────────────────────────────────────────────────────
# Must match AI_PROVIDER in the Next.js .env.local
# Options: anthropic | openai | grok | openrouter | huggingface
AI_PROVIDER=grok

# ── Direct provider keys (uncomment the one matching AI_PROVIDER) ─────────────
XAI_API_KEY=xai-...                  # AI_PROVIDER=grok
# ANTHROPIC_API_KEY=sk-ant-...       # AI_PROVIDER=anthropic
# OPENAI_API_KEY=sk-...              # AI_PROVIDER=openai

# ── Model overrides (optional — defaults shown) ───────────────────────────────
# Grok (xAI) — blitz: grok-4-fast-non-reasoning | sharp: grok-3-mini | keen: grok-3-fast | smart: grok-3
# GROK_BLITZ_MODEL=grok-4-fast-non-reasoning
# GROK_FAST_MODEL=grok-3-mini
# GROK_MID_MODEL=grok-3-fast
# GROK_SMART_MODEL=grok-3

# OpenRouter — route to any model via one key ─────────────────────────────────
# AI_PROVIDER=openrouter
# OPENROUTER_API_KEY=sk-or-v1-...
# OPENROUTER_MODEL=x-ai/grok-3                  # smart tier  (default: anthropic/claude-sonnet-4-6)
# OPENROUTER_MID_MODEL=x-ai/grok-3-fast         # keen tier   (default: OPENROUTER_MODEL)
# OPENROUTER_FAST_MODEL=x-ai/grok-3-mini        # sharp tier  (default: OPENROUTER_MODEL)

# HuggingFace ─────────────────────────────────────────────────────────────────
# AI_PROVIDER=huggingface
# HUGGINGFACE_API_KEY=hf_...
# HF_BASE_URL=https://router.huggingface.co/v1
# HF_BLITZ_MODEL=Qwen/Qwen2.5-1.5B-Instruct
# HF_FAST_MODEL=meta-llama/Llama-3.2-3B-Instruct
# HF_MID_MODEL=meta-llama/Llama-3.1-8B-Instruct
# HF_SMART_MODEL=meta-llama/Llama-3.3-70B-Instruct
